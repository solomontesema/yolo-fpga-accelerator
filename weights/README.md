# YOLOv2 Weight Files

This directory should contain the pre-trained YOLOv2 model weights in binary format required for running object detection.

## Required Files

The following binary files must be present in this directory before running the detection application:

1. **weights.bin** - Pre-trained network weights (~200MB)
2. **bias.bin** - Layer bias values (~1MB)
3. **weights_reorg.bin** - Reorganized weights for optimized inference (generated)

## Obtaining Weight Files

### Prerequisites

The weights in this project require a preprocessing step to convert from the standard Darknet weight format to the binary format used by this implementation.

### Step 1: Download Pre-trained YOLOv2 Weights

Download the official pre-trained YOLOv2 weights from the Darknet website:

```bash
wget https://pjreddie.com/media/files/yolov2.weights
```

Alternative sources:
- Official Darknet: https://pjreddie.com/darknet/yolo/
- Mirror repositories (search for "yolov2.weights")

**Expected File**: `yolov2.weights` (approximately 194 MB)

### Step 2a: Convert Weights to Binary Format (fp32)

Use the companion extractor/quantizer repo to produce the fp32 binaries expected here:

```
cd weights
git clone https://github.com/solomontesema/nn-weight-extractor.git
cd nn-weight-extractor
# Follow the README in that repo to export YOLOv2 weights:
# - Run the float32 export script to emit weights.bin and bias.bin
```

After running the extractor, copy or link the generated `weights.bin` and `bias.bin` into this `weights/` directory.

### Step 2b (optional): Convert Weights to Binary Format (int16)

In the same `nn-weight-extractor` repo, follow the int16 quantization/export steps:
```
cd weights/nn-weight-extractor
# Follow the README section for int16 export (activation-calibrated):
# - Generate weight_int16.bin and bias_int16.bin
# - Generate per-layer Q tables: weight_int16_Q.bin, bias_int16_Q.bin
# - Generate activation Q table: iofm_Q.bin (computed from a calibration set)
#   * Provide at least one representative image; more is better for coverage.
```

Place the generated int16 binaries alongside the fp32 ones in this `weights/` directory.

### Step 3: Verify Weight Files

After obtaining the binary weight files, verify they are in the correct location:

```bash
ls -lh weights/
```

Expected output should show:
```
-rw-r--r-- 1 user user 1.2M  bias.bin
-rw-r--r-- 1 user user 203M  weights.bin
```

Verify file integrity by checking sizes:
- `bias.bin`: Approximately 1-2 MB
- `weights.bin`: Approximately 200-205 MB

### Step 4: Generate Reorganized Weights

Once the raw binaries are in place, generate the reorganized weight file:

```bash
cd ..  # Return to project root
make gen
# fp32 (default)
./yolov2_weight_gen
# int16
./yolov2_weight_gen --precision int16
```

This creates `weights/weights_reorg.bin` (fp32) and `weights/weights_reorg_int16.bin` (int16) optimized for the inference engine.

## File Descriptions

### weights.bin
Contains all convolutional layer weights in float32 format. The weights are stored layer-by-layer in the order defined by the network configuration.

**Format**: Sequential float32 values
**Size**: ~200 MB
**Layout**: [Layer0_weights][Layer1_weights]...[LayerN_weights]

### bias.bin
Contains bias values for all layers that use biases (convolutional layers with batch normalization or direct biases).

**Format**: Sequential float32 values
**Size**: ~1-2 MB
**Layout**: [Layer0_biases][Layer1_biases]...[LayerN_biases]

### weights_reorg.bin (Generated)
Reorganized version of weights.bin optimized for tiled execution and hardware acceleration. This file is automatically generated by the `yolov2_weight_gen` executable.

**Format**: Sequential float32 values (reorganized)
**Size**: Same as weights.bin (~200 MB)
**Purpose**: Optimizes memory access patterns for better performance

## Troubleshooting

### Missing Weight Files

**Problem**: `weights.bin` or `bias.bin` not found

**Solutions**:
1. Verify you've completed the weight conversion step
2. Check file permissions (should be readable)
3. Ensure files are in the `weights/` directory
4. Contact the original project maintainer for conversion scripts

### Incorrect File Sizes

**Problem**: File sizes don't match expected values

**Solutions**:
1. Re-download the original yolov2.weights
2. Verify the conversion process completed successfully
3. Check for partial downloads or corrupted files
4. Ensure using YOLOv2 weights (not YOLOv3 or other variants)

### Regeneration Required

**Problem**: Need to regenerate `weights_reorg.bin`

**Solution**:
```bash
rm weights/weights_reorg.bin
make gen
./yolov2_weight_gen      # fp32
./yolov2_weight_gen --precision int16   # int16 path
```

### Memory Errors During Loading

**Problem**: Out of memory when loading weights

**Solutions**:
1. Ensure system has at least 2GB available RAM
2. Close other applications
3. Check for memory leaks in modifications
4. Verify weight file isn't corrupted (check size)

## Alternative Weight Sources

If official weights are unavailable:

1. **Trained Weights**: Use weights from a model trained on your own data
2. **Community Mirrors**: Search for "yolov2.weights mirror"
3. **Alternative Formats**: Convert from other frameworks (PyTorch, TensorFlow) using conversion tools

**Warning**: Ensure any alternative weights:
- Match the network architecture in `config/yolov2.cfg`
- Are trained on compatible datasets (80 classes for COCO)
- Use the same input dimensions (416x416)

## Weight File Security

**Important Security Notes**:
- Only download weights from trusted sources
- Verify checksums when available
- Binary weight files can be large; ensure sufficient disk space
- Weight files may contain model intellectual property; respect licensing

## Advanced: Custom Weights

To use custom-trained weights:

1. Train YOLOv2 on your dataset using Darknet or compatible framework
2. Convert the resulting weights to binary format
3. Update `config/yolov2.cfg` to match your network architecture
4. Update `config/coco.names` with your class labels
5. Place converted weights in this directory
6. Follow standard build process

## Format Specification

For developers implementing weight conversion:

### weights.bin Format
```
[float32] weight[0][0][0][0]
[float32] weight[0][0][0][1]
...
[float32] weight[L][N][C][K*K-1]
```

Where:
- L = layer index
- N = output channels
- C = input channels
- K = kernel size

### bias.bin Format
```
[float32] bias[0][0]
[float32] bias[0][1]
...
[float32] bias[L][N-1]
```

Where:
- L = layer index
- N = number of output channels for that layer

## Support

For weight conversion issues or questions:
1. Refer to original Darknet documentation
2. Check the preprocessing project if available
3. Review YOLOv2 weight format specifications
4. Consult the project issue tracker

---

**Note**: The binary weight format is specific to this implementation. Standard Darknet weights require conversion before use.
